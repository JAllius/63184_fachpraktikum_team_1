\section{Struktur}
\label{sec:struktur}
\ja
Bei dem Design des Projektes wurde ein großer Fokus auf Modularisierung und Skalierbarkeit gelegt. Ebenso wurden primär weit verbreitete Tools eingesetzt, um die Weiterentwicklung und Wartung des Projektes zu vereinfachen. Folglich sind die einzelnen Komponenten über bestimmte Schnittstellen miteinander verbunden. Innerhalb dieser ist eine Modifizierung oder ein Austausch der Komponenten unabhängig der anderen Komponenten umzusetzen. Dabei wurde Docker als Containerisierungslösung eingesetzt, da Docker eine sehr weit verbreitete Lösung darstellt \cite{sollfrankEvaluatingDockerLightweight2021}.

\subsection{Komponenten}
\label{subsec:komponenten}
\ja
Die einzelnen Komponenten des Projekts werden als containerisierte Microservices ausgerollt. Dabei werden die folgenden Komponenten verwendet:

\begin{enumerate}
    \item Frontend Node: eine React-basierte Weboberfläche zur vereinfachten Nutzung durch den Anwender
    \item API Node: eine FastAPI-basierte API, über welche sämtliche Funktionen des Projektes angestoßen werden können
    \item Worker Node: ein Python-Container, in dem die MLCore-bezogenen Tasks ausgeführt werden
    \item MySQL: eine SQL-basierte Datenbank
    \item Redis: Messaging Host für Zuweisung von Celery Tasks von / an verschiedene API / Worker Nodes
    \item Flower: eine Weboberfläche zum Redis-Monitoring
\end{enumerate}

Besonders sind dabei die Frontend, API und Worker Nodes zu betrachten. Die verbleibenden Komponenten sind unmodifizierte 3rd-party Softwares.

Die Frontend Node stellt eine in Docker gewrappte React-Applikation dar. React stellt ist dabei ein weit verbreitetes JavaScript-Framework zur Erstellung von interaktiven Weboberflächen. Auf das Frontend wird in der \refsubsec{subsec:ux:webui} näher eingegangen.

API Nodes stellen dabei eine in Docker gewrappte FastAPI dar. FastAPI ist ein Python-Framework zur Erstellung von REST-APIs. Die API wird entweder über das Frontend oder direkt durch einen versierten Nutzer angesteuert und löst entsprechende Celery-Tasks aus. Die FastAPI-Schnittstelle wird in der \refsubsec{subsec:ux:fastapi} beschrieben.

Worker Nodes basieren auf einem Python-Dockerimage und bieten die Kernfunktionen von MLCore an, also die tatsächliche Datenverarbeitung. Diese Funktionen werden über Celery Tasks ausgeführt. In der \refsec{sec:mlcore} wird vertiefend auf MLCore eingegangen.

MySQL wurde aufgrund der weiten Verbreitung des Tools verwendet. So war MySQL 2023 die zweit-meistverwendeste Datenbank nach Oracle \cite{DBEnginesRanking}. Oracle wurde allerdings aufgrund der Lizenzbedingungen für dieses Projekt nicht in Betracht gezogen. Zudem wurde speziell eine SQL-basierte Datenbank verwendet, um die Vorteile einer effizienten Speicherung für strukturierte Metadaten zu nutzen. Dabei ist zu beachten, dass in der aktuellen Version Nutzer-Uploads nur eingeschränkt in der Datenbank gespeichert werden (siehe Sektion \ref{sec:perspektive}). Für eine direkte Speicherung z.B. von .csv-Uploads wären auch dokumentbasierte Datenbanken wie beispielsweise MongoDB in Betracht zu ziehen gewesen \cite{DocumentStoresDBEngines}.

Redis und Celery sind verbreitete Tools für Messaging. Diese Tools wurden aufgrund bestehender Erfahrungen im Team sowie der leichten Implementierung in Python gewählt. Flower wurde folglich als Monitoring-Tool für Redis gewählt.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{../structure_release.png}
    \caption{Containerisierte Projekt-Struktur}
    \label{fig:structure}
\end{figure*}

\subsection{Containerisierung}
\label{subsec:container}
\ja
Docker ist ein verbreitetes Tool zu Containerisierung von Anwendungen und Microservices. Auf einem Host wird die sogenannte Docker-Engine installiert. Über diese können isolierte Instanzen von Images als Container erstellt werden. Die Images selber werden durch eine \glqq Dockerfile\grqq\space beschrieben \cite{reisDevelopingDockerDockerCompose2022}. Dabei wird meist ein bereits vorhandenes Image um die gewünschte Funktionalität erweitert, z.B. indem der Projektcode in dem Image eingebunden wird. Dieses Vorgehen nennt sich \glqq Image Layering\grqq\cite{UnderstandingImageLayers0530}.

Ein so beschriebenes Image wird anschließend gebaut und kann dann leicht auf anderen Host-Systemen verwendet werden. Dazu können die Images beispielsweise in einem Repository (öffentlich) zur Verfügung gestellt werden oder als \glqq tar-Ball\grqq\space exportiert werden \cite{DockerHubContainer}\cite{DockerImage0100}. Dabei muss der Entwickler des Image wenige Vorkehrungen treffen um das Image auf einer Vielzahl an Hosts verwendbar zu machen: die Docker-Engine übernimmt einen Großteil des Aufwands.


\begin{figure*}
    \centering
    \lstinputlisting[basicstyle=\tiny]{./figures/docker-compose.yml}
    \caption{Beispiel: docker-compose.yml}
    \label{fig:compose}
\end{figure*}

Ebenso kann Docker genutzt werden, um mehrere Container zu deployen, zu vernetzen und diese von außen erreichbar gestalten. Dazu wird \glqq Docker compose\grqq\space genutzt. Hierbei wird die Struktur eines \glqq Compose-Stacks\grqq\space beschrieben. Hierbei werden die einzelnen Images, die Konfigurationen dieser sowie Netzwerke und Volumes beschrieben. 

Ein Beispiel, wie die einzelnen Komponenten/Container des Projektes in einem Compose-Stack verknüpft werden können, findet sich in Abbildung \ref{fig:compose}. EINZELNE TEILE ERKLÄREN



\subsection{Datenbank}
\label{subsec:db}
\hg
\lipsum

\section{Workflow}
\ja
\label{sec:workflow}
% TODO: pytest, CI
% TODO: problem: nicht alle features durch privates github ohne dev acc. Keine protected branches etc
\lipsum